# Demonstration of working application in Real Time (Text-to-speech) 
https://user-images.githubusercontent.com/42881984/138499697-200554f3-c233-454b-8983-2db8839524ec.mp4

# Demonstration of working application by Browsing Images (Text-to-speech) 
https://user-images.githubusercontent.com/42881984/138498968-f72dea3f-3355-44cc-a93f-ac3b469c3718.mp4

# Image-Captioning
Image Captioning refers to the process of generating textual description from an image based on the objects and actions in the image. It uses both Natural Language Processing and Computer Vision to generate the captions.
Encoder-Decoder Architecture is the baseline architecture for the task of image captioning. The Encoder is responsible for the task of extracting features of an image and encoding them.
These encoded features are fed to the decoder, which generates natural language captions after decoding the image features
# Decoder Model
![image](https://user-images.githubusercontent.com/42881984/138498245-4aa1ac30-8fe4-4162-8fb3-89e67170acf0.png)

# Loss Plot
![image](https://user-images.githubusercontent.com/42881984/138498356-cfd635ff-fe9e-416a-80de-66f24b401199.png)

# Comparison between InceptionV3 & InceptionResnetV2 
![image](https://user-images.githubusercontent.com/42881984/138498438-3410cb7e-c5b6-484c-9938-3d51dad86a31.png)

